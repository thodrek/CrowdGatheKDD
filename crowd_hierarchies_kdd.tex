% THIS IS AN EXAMPLE DOCUMENT FOR VLDB 2012
% based on ACM SIGPROC-SP.TEX VERSION 2.7
% Modified by  Gerald Weber <gerald@cs.auckland.ac.nz>
% Removed the requirement to include *bbl file in here. (AhmetSacan, Sep2012)
% Fixed the equation on page 3 to prevent line overflow. (AhmetSacan, Sep2012)
\listfiles
\documentclass{sig-alternate}
\usepackage{graphicx}
\usepackage{color}
\usepackage{balance}  % for  \balance command ON LAST PAGE  (only there!)
\usepackage{times}
\usepackage{url}
\usepackage{algorithm}
\usepackage[noend]{algorithmic}
\usepackage{subfigure}
\usepackage{xspace}
\usepackage[noend]{algorithmic}
\usepackage{enumerate}
\usepackage{multirow}
\usepackage{epstopdf}
\usepackage{cleveref}
\usepackage{soul}
%\usepackage[font={small,it}]{caption}

\newcommand{\squishlist}{
   \begin{list}{$\bullet$}
    {
      \setlength{\itemsep}{0pt}
      \setlength{\parsep}{3pt}
      \setlength{\topsep}{3pt}
      \setlength{\partopsep}{0pt}
      \setlength{\leftmargin}{1.5em}
      \setlength{\labelwidth}{1em}
      \setlength{\labelsep}{0.5em} } }

\newcommand{\squishend}{
    \end{list}  }

\renewcommand*\ttdefault{cmvtt}

%\makeatletter
%\def\@copyrightspace{\relax}
%\makeatother


\newcommand{\argmax}{\operatornamewithlimits{arg\ max}}

\newcommand{\eat}[1]{}
\newcommand{\todo}[1]{\textcolor{red}{{TODO: #1}}}
\newcommand{\add}[1]{\textcolor{red}{{ADD: #1}}}
\newcommand{\note}[1]{\textcolor{blue}{{#1}}}
\newcommand{\agp}[1]{\textcolor{blue}{{Aditya: #1}}}
\newcommand{\stitle}[1]{\vspace{0.5em}\noindent\textbf{#1}}


\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{problem}{Problem}
\newtheorem{reduction}{Reduction}
\newcommand{\domain}{\mathcal{D}}
\newcommand{\attributes}{\mathcal{A}_D}
\newcommand{\hierarchy}{\mathcal{H}_D}
\newcommand{\attrhierarchy}{\mathcal{H}_A}
\newcommand{\workers}{\mathcal{W}}
\newcommand{\uentities}{\mathcal{E}}
\newcommand{\queryvector}{{\bf Q_S}}

\newif\ifpaper
\papertrue % comment out to create technical report

\newif\iftr
%\trtrue % uncomment to create technical report



\begin{document}

% ****************** TITLE ****************************************

%\title{CrowdGather: Entity Extraction over Structured Domains}
\title{CRUX: Crowdsourced Data Extraction from the Long Tail}
\numberofauthors{3} 

%\author{
%	\alignauthor Theodoros Rekatsinas\\
%            \affaddr{University of Maryland, College Park} 
%                \email{thodrek@cs.umd.edu}
%            \alignauthor Amol Deshpande\\
%            \affaddr{University of Maryland, College Park} 
%                \email{amol@cs.umd.edu}
%            \alignauthor Aditya Parameswaran \\
%            \affaddr{University of Illinois, Urbana-Champaign} 
%                \email{adityagp@illinois.edu}
%}

\maketitle

\begin{abstract}
Structured data repositories, such as knowledge bases, ontologies, or taxonomies, have dramatically increased our ability to identify and interpret information. While successful in improving or enriching keyword search, question answering,  event detection, and recommender systems, structured data repositories suffer from a lack of fine-grained data in the {\em long tail.} Crowdsourcing, on the other hand, has been proven effective in extracting fine-grained information. However, current approaches for using the crowd to extract and collect data (e.g., list all modern philosophers) focus on asking the same query (e.g., ``list a modern philosopher'') repeatedly. As a result, they are wasteful, since a small number of popular entities are provided by many workers, leading to increased duplicates, with the less popular entities not being as prevalent in the set of extracted entities.  

In this paper, we develop CRUX, a CRowdsoUrced data eXtraction framework that significantly limits duplicate extractions (and thereby wasted cost) by leveraging attributes that characterize these entities. For instance, we can instead ask queries such as ``list a {em political} modern philosopher'', or ``list an {\em analytic} modern philosopher'', that allows us to explore a larger space of entities by asking targeted queries. However, the ability to ask richer queries comes with a host of issues, especially since many queries may return empty answers.  We develop new statistical tools to reason about the gain, i.e., the number of new distinct extracted entities, of issuing {\em further queries} under the presence of little to no information allowing us to effectively prune futile queries. We also develop algorithms to discover adaptive querying strategies that seek to maximize the number of distinct extracted entities under budget constraints. We evaluate our techniques on both synthetic and real-world datasets, demonstrating a yield of up to 4X over competing approaches for the same budget.
\end{abstract}

\input{sections/intro_new}
\input{sections/prelims}
\input{sections/solving}
\input{sections/gainestimators}
\input{sections/exps}
\input{sections/related}
\input{sections/conclusions}
\balance

%\ifpaper
%\scriptsize
%\fi
\bibliographystyle{abbrv}
\bibliography{crowd_hierarchies}

\appendix
\section{Proof of Theorem 1}
\label{sec:prth1}
We prove that the problem of Budgeted Crowd Entity Extraction is NP-hard. The proof is based on a reduction from the unbounded knapsack problem.

\begin{proof}
The problem is in NP since the size of every feasible querying policy is polynomially bounded in the size of the given instance and the gain and cost of the policy can be computed in polynomial time. We now show that the problem is NP-hard by reducing the unbounded knapsack problem to the problem of budgeted crowd entity extraction. 

The unbounded knapsack problem is a variation of the original knapsack problem that places no upper bound on the number of copies of each kind of item.  In particular, for the decision version of the unbounded knapsack problem we are given $A_1, A_2, \dots, A_n$ items types with positive integer values $r_1, r_2, r_3, \dots, r_n$ and weights $c_1, c_2, c_3, \dots, c_n$. We are also given a budget $\tau_c$ and a value $V$.  The question we seek to answer is if there is a subset of item types $S$ so that if item type $A_i \in S$ is selected $x_i$ times, then $\sum_{A_i \in S} x_i \cdot c_i \leq \tau_c$ and $\sum_{A_i \in S} x_i \cdot r_i \geq V$.

We know show a polynomial reduction $Q(\cdot)$ from the unbounded knapsack to the problem of budgeted crowd entity extraction.  Given the input to knapsack, construct an input for the budgeted crowd entity extraction problem as follows: We consider a domain described by a trivial poset that corresponds to a not directed set of nodes $\{v_1, v_2, \dots, v_n\}$. Each of these nodes $v_i$ corresponds to an item $A_i$. We also set $K^v = \{r_i\}$ and $L^v = \{l^*\}$ with $l^* = \lceil \max (B\frac{r_i}{c_i}) \rceil$. Thus the only allowed query configuration for a node $v_i$ is $q^{v_i}(r_i,E^*)$ such that $|E^*| = l^*$. The latter implies that for each node all retrieved items will be included in the exclude list. Without loss of generality we assume a large population of entities associated with each node. Given this domain and the aforementioned queries, each query $q^{v_i}(r_i,l*)$ at node $v_i$ returns exactly $v_i$ distinct entities every time. Clearly, the reduction described above takes linear time with respect to the number of items in the Knapsack instance. 

Let $X$ be a ``Yes'' instance for the unbounded knapsack problem, with $S$ the set of distinct item type indicators selected and $x_i$ be the number of times each item type $A_i$ was chosen. We now chose the following querying policy for the budgeted crowd entity extraction problem: fix an arbitrary ordering of item type indicators $i \in S$ and issue $x_i$ queries at each node $v_i$. The total cost of the querying policy is $\sum_{i \in S} x_i \cdot c_i = \tau_c$ and the total gain of the policy is $\sum_{i \in S} x_i \cdot r_i = V$, which is a ``Yes'' instance of the decision version of the budgeted crowd entity extraction problem. 

Conversely, if $Q(X)$ is a ``Yes'' instance of the budgeted crowd entity extraction problem, with $S$ the set of indicators corresponding to the queried nodes $v_i$and $x_i$ the number of queries issued at each node, we select to put in the Knapsack $x_i$ copies of the item type $A_i$. It is to see that the total weight of the items is $\sum_{i \in S} x_i \cdot c_i = \tau_c$ and the total value is $\sum_{i \in S} x_i \cdot r_i = V$, which is a ``Yes'' instance of the decision version of unbounded knapsack problem. This completes the reduction. 
\end{proof}

\end{document}
