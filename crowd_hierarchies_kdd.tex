% THIS IS AN EXAMPLE DOCUMENT FOR VLDB 2012
% based on ACM SIGPROC-SP.TEX VERSION 2.7
% Modified by  Gerald Weber <gerald@cs.auckland.ac.nz>
% Removed the requirement to include *bbl file in here. (AhmetSacan, Sep2012)
% Fixed the equation on page 3 to prevent line overflow. (AhmetSacan, Sep2012)
\listfiles
\documentclass{sig-alternate}
\usepackage{graphicx}
\usepackage{color}
\usepackage{balance}  % for  \balance command ON LAST PAGE  (only there!)
\usepackage{times}
\usepackage{url}
\usepackage{algorithm}
\usepackage[noend]{algorithmic}
\usepackage{subfigure}
\usepackage{xspace}
\usepackage[noend]{algorithmic}
\usepackage{enumerate}
\usepackage{multirow}
\usepackage{epstopdf}
\usepackage{cleveref}
\usepackage{soul}
%\usepackage[font={small,it}]{caption}

\newcommand{\squishlist}{
   \begin{list}{$\bullet$}
    {
      \setlength{\itemsep}{0pt}
      \setlength{\parsep}{3pt}
      \setlength{\topsep}{3pt}
      \setlength{\partopsep}{0pt}
      \setlength{\leftmargin}{1.5em}
      \setlength{\labelwidth}{1em}
      \setlength{\labelsep}{0.5em} } }

\newcommand{\squishend}{
    \end{list}  }

\renewcommand*\ttdefault{cmvtt}

%\makeatletter
%\def\@copyrightspace{\relax}
%\makeatother


\newcommand{\argmax}{\operatornamewithlimits{arg\ max}}

\newcommand{\eat}[1]{}
\newcommand{\todo}[1]{\textcolor{red}{{TODO: #1}}}
\newcommand{\add}[1]{\textcolor{red}{{ADD: #1}}}
\newcommand{\note}[1]{\textcolor{blue}{{#1}}}
\newcommand{\agp}[1]{\textcolor{blue}{{Aditya: #1}}}
\newcommand{\stitle}[1]{\vspace{0.5em}\noindent\textbf{#1}}


\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{problem}{Problem}
\newtheorem{reduction}{Reduction}
\newcommand{\domain}{\mathcal{D}}
\newcommand{\attributes}{\mathcal{A}_D}
\newcommand{\hierarchy}{\mathcal{H}_D}
\newcommand{\attrhierarchy}{\mathcal{H}_A}
\newcommand{\workers}{\mathcal{W}}
\newcommand{\uentities}{\mathcal{E}}
\newcommand{\queryvector}{{\bf Q_S}}

\newif\ifpaper
\papertrue % comment out to create technical report

\newif\iftr
%\trtrue % uncomment to create technical report



\begin{document}

% ****************** TITLE ****************************************

%\title{CrowdGather: Entity Extraction over Structured Domains}
\title{Crowdsourced Data Extraction from the Long Tail}
\numberofauthors{3} 

%\author{
%	\alignauthor Theodoros Rekatsinas\\
%            \affaddr{University of Maryland, College Park} 
%                \email{thodrek@cs.umd.edu}
%            \alignauthor Amol Deshpande\\
%            \affaddr{University of Maryland, College Park} 
%                \email{amol@cs.umd.edu}
%            \alignauthor Aditya Parameswaran \\
%            \affaddr{University of Illinois, Urbana-Champaign} 
%                \email{adityagp@illinois.edu}
%}

\maketitle

%\begin{abstract}
%Crowdsourced entity extraction is often used to acquire data for many applications, including recommendation systems, construction of aggregated listings and directories, and knowledge base construction. Current solutions focus on entity extraction using a single query, e.g., only using ``give me another restaurant'', when assembling a list of all restaurants. Due to the cost of human labor, solutions that focus on a single query can be highly impractical.
%
%In this paper, we leverage the fact that entity extraction often focuses on {\em structured domains}, i.e., domains that are described by a collection of attributes, each potentially exhibiting hierarchical structure. Given such a domain, we enable a richer space of queries, e.g., ``give me another Moroccan restaurant in Manhattan that does takeout''. Naturally, enabling a richer space of queries comes with a host of issues, especially since many queries return empty answers. We develop new statistical tools that enable us to reason about the gain of issuing {\em additional queries} given little to no information, and show how we can exploit the overlaps across the results of queries for different points of the data domain to obtain accurate estimates of the gain. We cast the problem of {\em budgeted entity extraction} over large domains as an adaptive optimization problem that seeks to maximize the number of extracted entities, while minimizing the overall extraction costs. We evaluate our techniques with experiments on both synthetic and real-world datasets, demonstrating a yield of up to 4X over competing approaches for the same budget.
%\end{abstract}

\begin{abstract}
Crowdsourced entity extraction is key to collecting fine grained information for many applications, including recommendation systems, listings and directories construction, and knowledge base construction. Current solutions rely on repeatedly issuing fixed queries to workers asking them to list entities satisfying specific predicates, e.g., ``list a {\bf person} in today's NY Times''. This results to duplicate extractions and may significantly limiting the total number of distinct entities extracted. The proposed methods can be impractical when operating under a monetary budget as they overlook the ubiquitous long-tail phenomenon in extraction tasks, i.e., the fact that a small number of popular entities is provided by many workers, leading to increased duplicates, while a large number of not so popular entities is provided only by a small number of workers.

In this paper, we develop CrowdEX,  a crowdsourced data extraction framework that significantly limits duplicate extractions by adaptively updating the predicates of extraction queries to target long tail entities, e.g., it may adapt the initial query to ``list a {\bf Greek politician} in today's NY Times'' to target a more focused entity group. We leverage the fact that entity extraction often focuses on {\em structured domains}, i.e., domains described by a collection of attributes, to allow for richer queries with different predicate combinations. The latter comes with a host of issues, especially since many queries may return empty answers. We develop new statistical tools to reason about the gain, i.e., the number of new distinct extracted entities, of issuing {\em further queries} under the presence of little to no information allowing us to effectively prune futile queries. We also develop algorithms to discover adaptive querying strategies that seek to maximize the number of distinct extracted entities under budget constraints. We evaluate our techniques on both synthetic and real-world datasets, demonstrating a yield of up to 4X over competing approaches for the same budget.
\end{abstract}

\input{sections/intro_new}
\input{sections/prelims}
\input{sections/gainestimators}
\input{sections/solving}
\input{sections/exps}
\input{sections/related}
\input{sections/conclusions}
\balance

%\ifpaper
%\scriptsize
%\fi
\bibliographystyle{abbrv}
\bibliography{crowd_hierarchies}

\end{document}
