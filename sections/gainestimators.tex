%!TEX root = ../crux-sigconf.tex

\section{Estimating the Gain of Queries}
\label{sec:gainestimators}
As discussed previously, crowd entity extraction queries are equivalent to retrieving samples from a population of items following an unknown popularity distribution. Deciding which query to issue is dictated by the estimated gain of each query, i.e., the expected number of newly extracted entities. Estimating the gain of a query requires reasoning about the population percentage covered by all entities extracted by previous queries as well as the expected number of unseen entities in the underlying population.
Prior work~\cite{trushkowsky:2013,DBLP:journals/cacm/TrushkowskyKS16} studied the problem of estimating the aforementioned quantities for queries of the form ``list one more entity'', drawing from species richness estimation~\cite{chao:1992},
the problem of estimating the number of distinct species using samples from the underlying population. The proposed techniques extend an estimator from Chao et al.~\cite{chao:1992} and do not consider queries with exclude lists or queries on non-root nodes of the poset. Moreover, the original Chao estimator has been shown to exhibit negative biases~\cite{hwang:2010, shen:2003}, i.e., it underestimates the expected gain. The latter is worse in the presence of little information. Negative biases can severely impact entity extraction since nodes that contain entities from the long tail of the popularity distribution may never be queried as they may be deemed to have zero population. In this section, we first review the existing methodology for estimating the gain of a query, and then discuss how these estimators can be extended to consider support a poset (\Cref{sec:indirectsampling}) and exclude lists (\Cref{sec:excludelist}). 
Finally, we propose a new gain estimator for queries $q^v(k,E)$ that exhibits lower biases, and thus, improved performance, in the presence of little information compared to previous techniques (\Cref{sec:newestim}).


\subsection{Single-Node Estimators without Exclusion}
\label{sec:prevest}
Consider a specific node $v \in \hierarchy$. 
\iftr Prior work considers samples with replacement retrieved from the population associated with $v$ and does not consider an exclude list. 
\fi
Let $Q$ be the set of all existing samples retrieved by issuing queries at $v$ without an exclude list. 
These samples can be combined into a single sample, referred to as a {\em running sample}, corresponding to a multiset of size $n = \sum_{q \in Q} {\sf size}(q)$. Let $f_i$ denote the number of entities that appear $i$ times in this unified sample, $f_0$ denote the number of unseen entities from the population under consideration, and $C$ be the population coverage of the unified sample, i.e., the fraction of the population covered by the sample. We have that $C = \frac{f_1 + f_2 + ..}{f_0 + f_1 + ...}$.
A new query $q^v(k,\emptyset)$ is equivalent to increasing the size of the unified sample by $k$, thus, its gain is the number of new distinct entities included in the increased sample. Originally, Shen et al.~\cite{shen:2003} proposed an estimator for the number of new species $\hat{N}_{Shen}$ that would be found in an increased sample of size $k$. The approach assumes that unobserved entities have equal relative popularity. An estimate of the unique elements found in an increased sample of size $k$ is given by:

{\scriptsize \begin{equation}
\label{eq:shen}
\hat{N}_{Shen} = f_0\left( 1 - \left(1 - \frac{1 - C}{f_0}\right)^k\right)
\end{equation}}

For crowdsourced entity extraction, the term of Shen's formula in parenthesis corresponds to the probability that at least one unseen entity will be present in the result of a query asking for $k$ more entities. Thus, multiplying this quantity with the number of unseen entities $f_0$ corresponds to the expected number of unseen entities in the result of $q^v(k,\emptyset)$.

The quantities $f_0$ and $C$ are unknown and need to be estimated for the population of node $v$ using the observed entities in the running sample for $v$. The coverage can be estimated by the Good-Turing estimator $\hat{C} = 1 - \frac{f_1}{n}$ for the retrieved sample. 
 \iftr
On the other hand, multiple estimators have been proposed for estimating the number of unseen entities $f_0$.
Trushkowsky et al.~\cite{trushkowsky:2013} proposed a variation of the Chao et al.~\cite{chao:1992} estimator for $f_0$. Nevertheless, the authors argue that the original estimator proposed by Chao performs similarly with their approach when estimating the gain of an additional query. 
\fi
\ifpaper
To estimate $f_0$, the number of unseen items, the Chao et al.~\cite{chao:1992} estimator is known to do well~\cite{DBLP:journals/cacm/TrushkowskyKS16,trushkowsky:2013}.
\fi
The Chao estimator relies on sample coverage $C$ and the estimated skew of the underlying popularity distribution. The latter is estimated via the information in the available $f_i$ counts~\cite{chao:1992}. Recently, Hwang et al.~\cite{hwang:2010} proposed an alternative estimator for $f_0$ that is more robust in the presence of little information and utilizes a regression technique that exploits the information available in all $f_i$ counts.  

\subsection{Indirect Sampling}
\label{sec:indirectsampling}
Given a structured domain, the extracted entities for a node $v$ can be obtained either by querying $v$ directly or by indirect information flowing to $v$ by queries at other nodes connected to $v$. We refer to the latter case as {\em indirect sampling}. Eventually, we have two different kinds of samples: (i) those that are extracted by the {\bf entire population} of $v$, and (ii) those that are extracted by sampling {\bf only a part of the population} of $v$. 
\begin{figure}
	\begin{center}
	\vspace{-10pt}
	\includegraphics[clip,scale=0.25]{figs/exampleQuery.eps}	
	\vspace{-10pt}
	\caption{Querying the red node reveals entities from the green nodes.}
	\label{fig:query}
	\vspace{-10pt}
	\end{center}
\end{figure}
We use an example (\Cref{fig:query}) using the poset in \Cref{fig:eventslattice}, to illustrate these two cases. Assume a query $q(k,0)$ at node \{EventType X1\} whose result contains entities only from node \{X1,ST2\}. The green nodes in \Cref{fig:query} are nodes for which samples are obtained indirectly without querying them. Notice, that all these nodes are ancestors of \{X1,ST2\}. We have:
\squishlist
\item The samples for nodes \{X1, C1\} and \{X1,ST2\} are obtained by their {\em entire population} since node \{EventType X1\} is an ancestor of both and its population fully contains the populations of \{X1,C1\} and \{X1,ST1\}. 
\item The samples for nodes \{ \}, \{Country C1\} and \{State ST2\} are obtained only by a part of their population since the population of node \{EventType X1\} does not fully contain the populations of these nodes. 
\squishend

Samples of both types are used to estimate the gain of a query. To do so we merge the extracted entities for each node into a single sample and treat the unified sample as being extracted from the entire population. As we discuss later in \Cref{sec:solving}, we develop querying strategies that traverse the poset $\hierarchy$ in a top-down approach, hence, the number of samples belonging in the first category, i.e., samples retrieved considering the entire population of a node, dominates the number of samples retrieved by considering only part of a node's population. 
\iftr
Moreover, it has been shown by Hortal et al.~\cite{hortal2006evaluating} that species estimators, thus, our gain estimators, are insensitive when samples from different sub-populations are merged into a unified sample. 
While investigating the effect of indirect sampling further would be interesting, we found in our experiments that all gain estimators perform well when samples are aggregated.
\fi

\subsection{Exclude Lists and Negative Answers}
\label{sec:excludelist}
A query $q^v(k, E)$ with $E \ne \emptyset$ issued at node $v \in H_D$ effectively limits the sampling to a subset of the population corresponding to node $v$. To estimate the expected return of such a query, we need to update the estimates $\hat{f}_0$ and $\hat{C}$ before applying \Cref{eq:shen}, by removing entities in $E$ from the running sample for node $v$ and updating the frequency counts $f_i$ and sample size $n$. The above requires that the exclude list is known, discussed in \Cref{sec:config}.

Finally, we consider the effect of {\em negative answers} on estimating the gain of future queries. It is possible to issue a query at a specific node $v \in \hierarchy$ and receive no entities, i.e., we receive a negative answer. This is an indication that either underlying entity population of $v$ is empty. In such a scenario, we assign the expected gain of future queries at $v$ and all its descendants to zero. Another type of negative answer corresponds to issuing a query at an ancestor node $u$ of $v$ and receiving no entities for $v$. In this case, we do not update our estimates for node $u$ as entities from other descendants of $u$ may be more popular than entities associated with $u$.

\iftr
Finally, we consider the effect of {\em negative answers} on estimating the gain of future queries. It is possible to issue a query at a specific node $v \in \hierarchy$ and receive no entities, i.e., we receive a negative answer. We distinguish negative answers into two categories: (i) negative answers for a queries at a node $v$ for which we have already retrieved entities, and (ii) negative answers for queries at a node $v$ for which we have observed no entities. The first type of negative answer is indicative of entities in $v$ having low-popularity and is directly handled by the species estimators: after a query with a negative answer the total sample size increases while frequencies $f_i$ remain the same, thus, the estimated popularity is adjusted. The second type of negative answers offers evidence that the population of $v$ is empty. To handle this, one can model the existence of entities in a node with a Bernoulli random variable (with zero indicating that no items are available and one that there exists at least one item). Negative answers correspond to evidence of this variable being zero, and thus,  worker answers can be used to estimate the probability of this variable being one. If this variable is estimated to be zero with high-confidence we assign the expected gain of future queries at $v$ and all its descendants to zero.

To promote robustness against noisy workers one can use a Bayesian prior---ranging from strong priors such as Haldane's prior or Jeffrey's prior to weaker ones such as a Uniform prior. Identifying the right prior can be application specific. For exposition purposes, in the remainder of the paper we use Haldane's prior, which assumes that workers are accurate and, thus, a single negative answer is sufficient to obtain a high-confidence estimate.
\fi

\subsection{Direct Gain Estimation}
\label{sec:newestim}
The techniques reviewed in \Cref{sec:prevest} result in negative bias when the number of observed entities represents only a {\em small fraction} of the entire population~\cite{hwang:2010, shen:2003}. This holds for the large and sparse domains we consider. Bias is introduced as all techniques rely on \Cref{eq:shen}. To eliminate negative bias, we propose a direct estimator for the gain of queries $q^v(k,E)$ that does not use \Cref{eq:shen}. We extend the approach in Hwang~\cite{hwang:2010} and use a regression based technique that captures the structural properties of the expected gain function.
\ifpaper
 The proofs for the results below are 
in~\cite{cruxsup}.
\fi

Let $S$ be the total number of entities in the population and $p_i$ the abundance probability (i.e., popularity) of entity $i$. Given a sample of size $n$ (where n corresponds to the total sum of sizes for all previously issued queries), define $K(n)$ to be $K(n) = \frac{\sum_{i=1}^S (1-p_i)^n}{\sum_{i=1}^S p_i(1-p_i)^{n-1}}$. First, we focus on queries without an exclude list. Later we relax this and discuss queries with exclude lists. We have the following theorem on query gain:

\begin{theorem}[{\bf Direct Gain Estimation}]
\label{newgain}
Given a node $v \in \hierarchy$ and a corresponding entity sample of size $n$, let $f_1$ and $f_2$ denote the number of entities that appear exactly once (i.e., singletons) and exactly twice respectively. Let $G$ denote the number of new items retrieved by a query $q(m,\emptyset)$. We have:

\vspace{-10pt}{\small \begin{equation}
\label{eq:dirgain}
G = \frac{1}{(1 + \frac{K^{\prime}}{n+m})}(K\frac{f_1}{n} - K^{\prime}\frac{f_1(1-\frac{1}{n}2\frac{f_2}{f_1})^m}{n+m})
\end{equation}}
where $K = K(n)$ and $K^{\prime} = K(n+m)$.
\end{theorem}
\iftr
\begin{proof}
To derive the new estimator we make used of the generalized jackknife procedure for species richness estimation~\cite{heltshe1983estimating}. Given two (biased) estimators of $S$, say $\hat{S}_1$ and $\hat{S}_2$, let $R$ be the ratio of their biases:
\begin{equation}
R = \frac{E(\hat{S}_1) - S}{E(\hat{S}_2) - S}
\end{equation}
By the generalized jackknife procedure, we can completely eliminate the bias resulting from either $\hat{S}_1$ or $\hat{S}_2$ via
\begin{equation}
S = G(\hat{S}_1, \hat{S}_2) = \frac{\hat{S}_1 - R\hat{S}_2}{1 - R}
\label{eq:jknife}
\end{equation}
provided the ratio of biases $R$ is known. However, $R$ is unknown and needs to be estimated. 

Let $D_n$ denote the number of unique entities in a unified sample of size $n$. We consider the following two biased estimators of $S$: $\hat{S_1} = D_n$ and $\hat{S}_2 = \sum_{j=1}^n D_{n-1}(j)/n = D_n - f_1/n$ where $D_{n-1}(j)$ is the number of species discovered with the $j$th observation removed from the original sample. Replacing these estimators in \Cref{eq:jknife} gives us:
\begin{equation}
S = D_n +\frac{R}{1-R}\frac{f_1}{n}
\end{equation}
Similarly, for a sample of increased size $n+m$ we have:
\begin{equation}
S = D_{n+m} +\frac{R^{\prime}}{1-R^{\prime}}\frac{f^{\prime}_1}{n+m}
\end{equation}
where $R^{\prime}$ is the ratio of the biases and $f^{\prime}_1$ the number of singleton entities for the increased sample. Let $K = \frac{R}{1-R}$ and $K^{\prime} = \frac{R^{\prime}}{1-R^{\prime}}$. Taking the difference of the previous two equations we have:
\begin{equation}
D_{n+m} - D_{n} = K\frac{f_1}{n} - K^{\prime}\frac{f^{\prime}_1}{n+m}
\end{equation}
Therefore, we have:
\begin{equation}
\label{eq:new}
G = K\frac{f_1}{n} - K^{\prime}\frac{f^{\prime}_1}{n+m}
\end{equation}
We need to estimate $K$, $K^{\prime}$ and $f^{\prime}_1$. We start with $f^{\prime}_1$, which denotes the number of singleton entities in the increased sample of size $n+m$. Notice, that $f^{\prime}_1$ is not known since we have not obtained the increased sample yet, so we need to express it in terms of $f_1$, i.e., the number of singletons, in the running sample of size $n$. We have:
\begin{equation}
f^{\prime}_1 = G + f_1 - f_1^c
\end{equation}
where $f_1^c$ denotes the number of old singleton entities from the sample of size $n$ that appeared in the additional query of size $m$. Let $E_1$ denote the set of singleton entities in the old sample of size $n$. We approximate $f_1^c$ by its expected value:
\begin{equation}
\hat{f}_1^c = \sum_{e \in E_1} \Pr[\mbox{e appears in query of size $m$}]
\end{equation}
We compute the probability of an old singleton entity appearing in an additional query as follows. Let $p_e$ denote the popularity of entity $e$. As described before, an additional query of size $m$ corresponds to taking a sample of size $m$ from the underlying entity population without replacement. However, $m$ is significantly smaller compared to the size of the underlying population, thus, we can consider a that taking a sample of size $m$ corresponds to taking a sample {\em with replacement}. Following this we have that:
\begin{equation}
\Pr[\mbox{e appears in query of size $m$}] = 1 - (1-p_e)^m
\end{equation}
Following a standard approach in the species estimation literature we assume that the popularity of retrieving a singleton entity again is the same for all singleton entities. This popularity can be computed using the corresponding Good-Turing estimator considering the running sample. We have:
\begin{equation}
\forall e \in E_1, p_e = p_1 = \hat{\theta}(1) = \frac{1}{n}2\frac{f_2}{f_1}
\end{equation}
where $f_2$ is the number of entities that appear twice in the sample and $f_1$ is the number of singletons. 
Eventually we have that:
\begin{equation}
\hat{f}_1^c = f_1(1 - (1-p_1)^m)
\end{equation}
and
\begin{equation}
f^{\prime}_1 = G + f_1(1-p_1)^m
\end{equation}
Replacing the last equation in \Cref{eq:new} we have:
\begin{align}
&G = K\frac{f_1}{n} - K^{\prime}\frac{G + f_1(1-p_1)^m}{n+m} \nonumber \\
&G = K\frac{f_1}{n} - K^{\prime}\frac{G}{n+m} - K^{\prime}\frac{f_1(1- P)}{n+m} \nonumber \\
&G(1 + \frac{K^{\prime}}{n+m}) = K\frac{f_1}{n} - K^{\prime}\frac{f_1(1- P)}{n+m} \nonumber \\
&G = \frac{1}{(1 + \frac{K^{\prime}}{n+m})}(K\frac{f_1}{n} - K^{\prime}\frac{f_1(1-p_1)^m}{n+m}) \nonumber
\end{align}
\end{proof}
\fi
All quantities apart from $K$ and $K^{\prime}$ in \Cref{eq:dirgain} are known. The value of $K$ can be estimated using the regression approach of Hwang and Shen~\cite{hwang:2010}. \iftr From the Cauchy-Schwarz inequality we have that:
\begin{equation}
K = \frac{\sum_{i=1}^S (1-p_i)^n}{\sum_{i=1}^S p_i(1-p_i)^{n-1}} \geq \frac{(n-1)f_1}{2f_2}
\end{equation}
This can be generalized to:
\begin{equation}
K=\frac{nf_0}{f_1} \geq \frac{(n-1)f_1}{2f_2} \geq \frac{(n-2)f_2}{3f_3} \geq \dots
\end{equation}
Let $g(i) = \frac{(n-i)f_i}{(i+1)f_{i+1}}$. From the above we have that the function $g(x)$ is a smooth monotone function for all $x \geq 0$. Moreover, let $y_i$ denote a realization of $g(i)$ mixed with a random error. Hwang and Shen how one can use an exponential regression model to estimate $K$. The proposed model corresponds to:
\begin{equation}
y_i = \beta_0\exp(\beta_1i^{\beta_2}) + \epsilon_i
\end{equation}
where $i = 1, \dots, n-1$, $\beta_0 > 0$, $\beta_1 < 0$, $\beta_2 >0$ and $\epsilon_i$ denotes random errors. It follows that $K = \beta_0$. \fi
To estimate the value of $K^{\prime}$ for an increased sample of size $n+m$, we first show that $K$ increases monotonically as the size of the running sample increases. 

\begin{lemma}
\label{monotonicity}
The function $K(n) = \frac{\sum_{i=1}^S (1-p_i)^n}{\sum_{i=1}^S p_i(1-p_i)^{n-1}}$ increases monotonically, i.e., $K(n+m) \geq K(n), \forall n,m > 0$.
\end{lemma}
\iftr
\begin{proof}
In the remainder of the proof we will denote $K(n+m)$ as $K^{\prime}$. By definition we have that $K = \frac{\sum_{i=1}^S (1-p_i)^n}{\sum_{i=1}^S p_i(1-p_i)^{n-1}}$ and $K^{\prime} = \frac{\sum_{i=1}^S (1-p_i)^{n+m}}{\sum_{i=1}^S p_i(1-p_i)^{n+m-1}}$. We want to show that:

{\small
\begin{align}
&\frac{\sum_{i=1}^S (1-p_i)^{n+m}}{\sum_{i=1}^S p_i(1-p_i)^{n+m-1}} \geq \frac{\sum_{i=1}^S (1-p_i)^n}{\sum_{i=1}^S p_i(1-p_i)^{n-1}} \nonumber \\
&\sum_{i=1}^S (1-p_i)^{n+m}\sum_{j=1}^S p_j(1-p_j)^{n-1} \geq \sum_{i=1}^S p_i(1-p_i)^{n+m-1}\sum_{j=1}^S (1-p_j)^n\nonumber \\
&\sum_{i,j:i\prec j}[(1-p_i)^{n+m}p_j(1-p_j)^{n-1} - p_i(1-p_i)^{n+m-1}(1-p_j)^n + \nonumber \\
& + (1-p_j)^{n+m}p_i(1-p_i)^{n-1} - p_j(1-p_j)^{n+m-1}(1-p_i)^n] \geq 0 \nonumber \\
%&\sum_{i,j:i\prec j}[(1-p_i)^{n}(1-p_j)^{n-1}p_j((1-p_i)^{m} - (1-p_j)^{m})  + \nonumber \\
%& - (1-p_j)^{n}p_i(1-p_i)^{n-1}((1-p_i)^{m} - (1-p_j)^{m}) \geq 0 \nonumber \\
&\sum_{i,j:i\prec j}[(1-p_i)^{n-1}(1-p_j)^{n-1}(p_j-p_i)((1-p_i)^{m} - (1-p_j)^{m}) \geq 0
\end{align}}

But the last inequality always holds since each term of the summation is positive. In particular, if $p_j \geq p_i$ then
also $1-p_i \geq 1-p_j$ and if $p_j \leq p_i$ then $1-p_i \leq 1-p_j$.
\end{proof}
\fi
Given its monotonicity, we model $K$ as a generalized logistic function of the form $K(x) = \frac{A}{1+exp(-G(x-D))}$. As we observe samples of different sizes for different queries we estimate $K$ as described above and therefore we observe different realizations of $f(\cdot)$. Thus, we can learn the parameters of $f$ and use it to estimate $K^{\prime}$. In the presence of an exclude list of size $l$ we follow the approach described in \Cref{sec:excludelist} to update the quantities $f_i$ and $n$ used above. 
 
%\subsection{Negative Answers and Gain Estimation}
%\label{sec:neg}
%Next, we study the effect of {\em negative answers} on estimating the gain of future queries. It is possible to issue a query at a specific node $v \in \hierarchy$ and receive no entities, i.e., we receive a negative answer. This is an indication that the underlying entity population of $v$ is empty. In such a scenario, we assign the expected gain of future queries at $v$ and all its descendants to zero. 
%
%Another type of negative answer corresponds to the scenario where we issue a query at an ancestor node $u$ of $v$ and receive no entities associated with $v$ but received some entities for $u$. Notice, that in this case, we do not have enough information to update our estimates for node $u$. The reason is that due to the restricted query size entities from other descendants of $u$ may be more popular with respect to the popularity distribution of $u$.