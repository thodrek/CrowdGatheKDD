%!TEX root = ../crux.tex

\section{Conclusions and Future Work}
\label{sec:conclusions}
We studied the problem of crowdsourced entity extraction over large and diverse data domains. We proved that the problem of budgeted crowdsourced entity extraction is NP-hard. We introduced CRUX, a novel crowdsourced entity extraction framework, that combines statistical techniques with an adaptive optimization algorithm to maximize the total number of unique entities extracted. We proposed a new regression-based technique for estimating the gain of further querying when the number of retrieved entities is small with respect to the total size of the underlying population. We also introduced a new algorithm that exploits the often known structure of the underlying data domain to devise adaptive querying strategies. CRUX extracts up to 300\% more entities compared to a collection of baselines, and for large sparse entity domains is at most 25\% away from an omniscient adaptive querying strategy with perfect information.

Some of the future directions for extending this work include reasoning about the quality and correctness of the extracted result as well as extending the proposed techniques to other types of information extraction tasks. As mentioned before, the techniques proposed in this paper do not deal with incomplete and imprecise information. However, there has been an increasing amount of literature on addressing these quality issues in crowdsourcing~\cite{ vox-populii, quality, nushi:14, raykar-whom-to-trust}. Combining these techniques, or entity resolution techniques~\cite{crowder} that reason about similarity of extracted entities, with our proposed framework is a promising future direction. Finally, it is of particular interest to apply the proposed framework to other budget sensitive information extraction applications including discovering valuable data sources for integration tasks~\cite{rekatsinas:2015, rekatsinas:2014} or curating an existing knowledge base~\cite{kondredi:2014}.