% THIS IS AN EXAMPLE DOCUMENT FOR VLDB 2012
% based on ACM SIGPROC-SP.TEX VERSION 2.7
% Modified by  Gerald Weber <gerald@cs.auckland.ac.nz>
% Removed the requirement to include *bbl file in here. (AhmetSacan, Sep2012)
% Fixed the equation on page 3 to prevent line overflow. (AhmetSacan, Sep2012)
\listfiles
%\documentclass{sig-alternate}
\documentclass[conference]{IEEEtran}
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{color}
\usepackage{balance}  % for  \balance command ON LAST PAGE  (only there!)
\usepackage{times}
\usepackage{url}
\usepackage{algorithm}
\usepackage[noend]{algorithmic}
\usepackage{subfigure}
\usepackage{xspace}
\usepackage[noend]{algorithmic}
\usepackage{enumerate}
\usepackage{multirow}
\usepackage{epstopdf}
\usepackage{cleveref}
\usepackage{soul}
%\usepackage[font={small,it}]{caption}

\newcommand{\squishlist}{
   \begin{list}{$\bullet$}
    {
      \setlength{\itemsep}{0pt}
      \setlength{\parsep}{3pt}
      \setlength{\topsep}{3pt}
      \setlength{\partopsep}{0pt}
      \setlength{\leftmargin}{1.5em}
      \setlength{\labelwidth}{1em}
      \setlength{\labelsep}{0.5em} } }

\newcommand{\squishend}{
    \end{list}  }

\renewcommand*\ttdefault{cmvtt}

%\makeatletter
%\def\@copyrightspace{\relax}
%\makeatother


\newcommand{\argmax}{\operatornamewithlimits{arg\ max}}

\newcommand{\eat}[1]{}
\newcommand{\todo}[1]{\textcolor{red}{{TODO: #1}}}
\newcommand{\add}[1]{\textcolor{red}{{ADD: #1}}}
\newcommand{\note}[1]{\textcolor{blue}{{#1}}}
\newcommand{\agp}[1]{\textcolor{blue}{{Aditya: #1}}}
\newcommand{\stitle}[1]{\vspace{0.5em}\noindent\textbf{#1}}


\newtheorem{definition}{Definition}
\newtheorem{example}{Example}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{problem}{Problem}
\newtheorem{reduction}{Reduction}
\newcommand{\domain}{\mathcal{D}}
\newcommand{\attributes}{\mathcal{A}_D}
\newcommand{\hierarchy}{\mathcal{H}_D}
\newcommand{\attrhierarchy}{\mathcal{H}_A}
\newcommand{\workers}{\mathcal{W}}
\newcommand{\uentities}{\mathcal{E}}
\newcommand{\queryvector}{{\bf Q_S}}

\newif\ifpaper
\papertrue % comment out to create technical report

\newif\iftr
%\trtrue % uncomment to create technical report



\begin{document}

% ****************** TITLE ****************************************

%\title{CrowdGather: Entity Extraction over Structured Domains}
\title{Adaptive Querying Strategies for Efficient Crowdsourced Data Extraction}
%\numberofauthors{3} 
%
%\author{
%	\alignauthor Theodoros Rekatsinas\\
%            \affaddr{University of Maryland, College Park} 
%                \email{thodrek@cs.umd.edu}
%            \alignauthor Amol Deshpande\\
%            \affaddr{University of Maryland, College Park} 
%                \email{amol@cs.umd.edu}
%            \alignauthor Aditya Parameswaran \\
%            \affaddr{University of Illinois, Urbana-Champaign} 
%                \email{adityagp@illinois.edu}
%}

\author{\IEEEauthorblockN{Theodoros Rekatsinas}
\IEEEauthorblockA{Stanford University\\
thodrek@cs.stanford.edu}
\and
\IEEEauthorblockN{Amol Deshpande}
\IEEEauthorblockA{University of Maryland, College Park\\
amol@cs.umd.edu}
\and
\IEEEauthorblockN{Aditya Parameswaran}
\IEEEauthorblockA{University of Illinois, Urbana-Champaign\\
adityagp@illinois.edu}}

\maketitle

\begin{abstract}
Crowdsourcing has been proven crucial to the extraction and collection of information about real-world entities (e.g., people, organizations, or real-world events) that belong to not-so-popular specialized data verticals. Existing crowdsourced data extraction solutions adopt non-adaptive querying strategies that repeatedly ask crowd-workers to list entities from a predetermined domain until a desired level of coverage is reached. Due to the cost of human labor, such solutions can be highly impractical as they are cost-agnostic and do not optimize crowd-queries to maximize the number of extracted entities with minimal monetary cost. In this paper, we design adaptive querying strategies that aim to maximize the number of extracted data for a given budget thereby dramatically improving the effectiveness and efficiency of crowdsourced data extraction techniques. We leverage two novel insights: {\em exploiting the structure of the domain of interest}, and {\em using exclude lists to limit the repeated extractions}. We apply these insights in developing CRUX, a CRowdsoUrced data eXtraction framework that optimizes crowdsourced entity extraction by dynamically adapting the queries issued against the crowd to minimize the number of duplicate extractions, and thereby the wasted cost. We develop new statistical tools to reason about the gain, i.e., the number of new distinct extracted entities, of issuing {\em further queries} under the presence of little to no information; this allows us to effectively prune futile queries. We also introduce algorithms to discover adaptive querying strategies that maximize the number of distinct extracted entities under budget constraints. We evaluate our techniques on both synthetic and real-world datasets, demonstrating an improvement of up to 300\% over competing approaches for the same budget.
\end{abstract}

\input{sections/intro_new}
\input{sections/prelims}
\input{sections/problem}
\input{sections/gainestimators}
\input{sections/solving}
\input{sections/exps}
\input{sections/related}
\input{sections/conclusions}
\balance

\bibliographystyle{abbrv}
\bibliography{crux}

\appendices
\input{sections/appendix}
\end{document}
